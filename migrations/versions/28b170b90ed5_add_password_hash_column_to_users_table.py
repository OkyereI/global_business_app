"""Add password_hash column to users table

Revision ID: 28b170b90ed5
Revises:
Create Date: 2025-07-19 14:32:38.180749

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from werkzeug.security import generate_password_hash # IMPORTANT: Add this import for hashing

# revision identifiers, used by Alembic.
revision = '28b170b90ed5'
down_revision = None # This should be 'None' if it's the first migration
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###

    # IMPORTANT: The original migration included op.drop_table('transactions').
    # If you have data in a 'transactions' table that is NOT managed by your
    # current SaleRecord model, and you want to keep it, you should comment
    # out or remove the following 'op.drop_table' line.
    # For safety and to focus on the password issue, it's commented out here.
    # If you are certain this table is obsolete, you can uncomment it.
    # op.drop_table('transactions')

    # Step 1: Add the new 'password_hash' column as nullable=True (temporarily)
    # This allows the column to be added without violating NOT NULL for existing rows.
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.add_column(sa.Column('password_hash', sa.String(length=255), nullable=True))

    # Step 2: Migrate data from 'password' to 'password_hash' by hashing existing passwords.
    # This is the crucial part for keeping user passwords.
    # It assumes your 'password' column still exists and contains plain-text passwords.
    # If the 'password' column was already dropped or doesn't exist, this step will fail.
    # If it fails, you will need to reset user passwords manually or via a "Forgot Password" flow.
    conn = op.get_bind()
    
    # Fetch all user IDs and their plain passwords from the 'password' column
    # We use text() for raw SQL to ensure we can select the 'password' column directly
    # even if it's not part of the current ORM model definition (which now uses password_hash).
    # This is safe within a migration context.
    users_data = conn.execute(sa.text("SELECT id, password FROM users")).fetchall()

    for user_id, plain_password in users_data:
        if plain_password is not None:
            # Hash the plain password
            hashed_password = generate_password_hash(plain_password)
            # Update the new password_hash column for this user
            conn.execute(sa.text(f"UPDATE users SET password_hash = :hashed_pw WHERE id = :user_id"),
                         {'hashed_pw': hashed_password, 'user_id': user_id})
        else:
            # Handle cases where existing 'password' might be NULL or empty.
            # Since password_hash will become NOT NULL, we must set a value.
            # A hash of an empty string or a known placeholder is a good option.
            hashed_placeholder = generate_password_hash('') # Hash of an empty string
            conn.execute(sa.text(f"UPDATE users SET password_hash = :hashed_pw WHERE id = :user_id"),
                         {'hashed_pw': hashed_placeholder, 'user_id': user_id})

    # Step 3: Drop the old 'password' column
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.drop_column('password')

    # Step 4: Alter 'password_hash' to nullable=False
    # Now that all existing rows have a hashed password, we can enforce NOT NULL.
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.alter_column('password_hash',
                       existing_type=sa.String(length=255),
                       nullable=False)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    # In downgrade, we revert the changes.
    # Note: We cannot "unhash" passwords. Downgrading will lose password data.
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.add_column(sa.Column('password', sa.VARCHAR(length=255), autoincrement=False, nullable=True)) # Make it nullable on downgrade
        batch_op.drop_column('password_hash')

    # Recreate 'transactions' table if it was dropped in upgrade.
    # This part should only be here if op.drop_table('transactions') was in upgrade().
    op.create_table('transactions',
    sa.Column('id', sa.VARCHAR(length=36), autoincrement=False, nullable=False),
    sa.Column('business_id', sa.VARCHAR(length=36), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.VARCHAR(length=36), autoincrement=False, nullable=True),
    sa.Column('transaction_id_display', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('transaction_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('total_amount', postgresql.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('payment_method', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('payment_status', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('transaction_date', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('last_updated', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('customer_name', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('customer_phone', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('original_transaction_id', sa.VARCHAR(length=36), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['business_id'], ['businesses.id'], name=op.f('transactions_business_id_fkey')),
    sa.ForeignKeyConstraint(['original_transaction_id'], ['transactions.id'], name=op.f('transactions_original_transaction_id_fkey')),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('transactions_user_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('transactions_pkey')),
    sa.UniqueConstraint('transaction_id_display', name=op.f('transactions_transaction_id_display_key'))
    )
    # ### end Alembic commands ###
