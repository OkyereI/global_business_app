"""Add company_id to CompanyTransaction table

Revision ID: 7ed505f3a493
Revises: a574fc167cb9
Create Date: 2025-08-28 10:49:57.477694

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '7ed505f3a493'
down_revision = 'a574fc167cb9'
branch_labels = None
depends_on = None



def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Corrected section for company_transactions
    with op.batch_alter_table('company_transactions', schema=None) as batch_op:
        # Step 1: Add the column as nullable. This allows the migration to succeed without a NotNullViolation.
        batch_op.add_column(sa.Column('company_id', sa.String(length=36), nullable=True))
        
        # Step 2: Create the foreign key.
        batch_op.create_foreign_key(None, 'companies', ['company_id'], ['id'])
        
        # These are the other commands from the original auto-generated script
        batch_op.alter_column('description',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.Text(),
               existing_nullable=True)
        batch_op.drop_column('notes')

    # The rest of your auto-generated commands go here without changes
    with op.batch_alter_table('businesses', schema=None) as batch_op:
        batch_op.alter_column('last_synced_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.create_unique_constraint(None, ['remote_id'])

    with op.batch_alter_table('companies', schema=None) as batch_op:
        batch_op.drop_constraint(batch_op.f('companies_company_id_key'), type_='unique')
        batch_op.drop_constraint(batch_op.f('uq_companies_name'), type_='unique')
        batch_op.drop_column('company_id')

    with op.batch_alter_table('inventory_items', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('uq_inventory_item_business_barcode'), postgresql_where='(barcode IS NOT NULL)')

    with op.batch_alter_table('sales_records', schema=None) as batch_op:
        batch_op.alter_column('synced_to_remote',
               existing_type=sa.BOOLEAN(),
               nullable=False)

    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.alter_column('password',
               existing_type=sa.VARCHAR(length=128),
               type_=sa.String(length=225),
               existing_nullable=False)


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.alter_column('password',
               existing_type=sa.String(length=225),
               type_=sa.VARCHAR(length=128),
               existing_nullable=False)

    with op.batch_alter_table('sales_records', schema=None) as batch_op:
        batch_op.alter_column('synced_to_remote',
               existing_type=sa.BOOLEAN(),
               nullable=True)

    with op.batch_alter_table('inventory_items', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('uq_inventory_item_business_barcode'), ['business_id', 'barcode'], unique=True, postgresql_where='(barcode IS NOT NULL)')

    with op.batch_alter_table('company_transactions', schema=None) as batch_op:
        batch_op.add_column(sa.Column('notes', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.alter_column('description',
               existing_type=sa.Text(),
               type_=sa.VARCHAR(length=255),
               existing_nullable=True)
        batch_op.drop_column('company_id')

    with op.batch_alter_table('companies', schema=None) as batch_op:
        batch_op.add_column(sa.Column('company_id', sa.VARCHAR(length=36), autoincrement=False, nullable=True))
        batch_op.create_unique_constraint(batch_op.f('uq_companies_name'), ['name'])
        batch_op.create_unique_constraint(batch_op.f('companies_company_id_key'), ['company_id'])

    with op.batch_alter_table('businesses', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='unique')
        batch_op.alter_column('last_synced_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)

    # ### end Alembic commands ###
